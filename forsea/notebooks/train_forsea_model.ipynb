{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "gpu = torch.device(\"cuda:0\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\n",
    "    \"/home/knowit/Home_Foresee/forseeModel/data/copernicus/datasets/norway_nrt.nc\"\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.dataloader import ForSeaDataset\n",
    "\n",
    "\n",
    "# ocean_data_path = '/home/knowit/Home_Foresee/forseeModel/data/copernicus/nrt/resampled/all_vars.nc'\n",
    "ocean_data_path = (\n",
    "    \"/home/knowit/Home_Foresee/forseeModel/data/copernicus/datasets/ocean_data.nc\"\n",
    ")\n",
    "route_data_path = (\n",
    "    \"/home/knowit/Home_Foresee/forseeModel/data/VMS_DCA_joined/cod_trawl.parquet\"\n",
    ")\n",
    "dataset = ForSeaDataset(\n",
    "    ocean_data_path, route_data_path, log_target=log_target, batched=True\n",
    ")\n",
    "# dataloader = DataLoader(dataset, batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "num_features = dataset.route_input.shape[1]\n",
    "for i in range(num_features):\n",
    "    plt.subplot(1, num_features, i + 1)\n",
    "    plt.hist(dataset.route_input[:, i], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X1, X2), y = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape, X2.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.EncoderDecoder import ForseaAutoEncoder\n",
    "\n",
    "ocean_data_shape = X1.shape\n",
    "route_data_features = X2.shape[1]\n",
    "\n",
    "model = ForseaAutoEncoder(\n",
    "    ocean_data_shape,\n",
    "    [16, 16, 16],\n",
    "    (3, 3),\n",
    "    route_data_features,\n",
    "    128,\n",
    "    1,\n",
    "    log_target=log_target,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "loss_history = []\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataset):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        (ocean_input, route_input), roundweight = data\n",
    "        if len(route_input) == 0:\n",
    "            continue\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(ocean_input, route_input)\n",
    "        loss = criterion(outputs, roundweight)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        print_period = 200\n",
    "        if i % print_period == print_period - 1:  # print every 2000 mini-batches\n",
    "            print(\n",
    "                f\"[{epoch + 1}, {i + 1:5d}] | output: {torch.mean(outputs)} | loss: {running_loss / print_period:.3f}\"\n",
    "            )\n",
    "            loss_history.append(running_loss / print_period)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.array(loss_history)\n",
    "plt.plot(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.ocean_data.x.values\n",
    "y = dataset.ocean_data.y.values\n",
    "X, Y = np.meshgrid(x, y)\n",
    "X_flat = X.ravel()\n",
    "Y_flat = Y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_date = pd.to_datetime(\"2022-09-01 12:00:00\")\n",
    "time_of_day = 0.3\n",
    "day_of_year = inference_date.day_of_year / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_array = np.zeros((len(X_flat), route_data_features))\n",
    "inference_array[:, 0] = time_of_day\n",
    "inference_array[:, 1] = day_of_year\n",
    "inference_array[:, 2] = X_flat\n",
    "inference_array[:, 3] = Y_flat\n",
    "inference_tensor = torch.from_numpy(inference_array).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_array = np.zeros(ocean_data_shape)\n",
    "for i, k in enumerate(dataset.ocean_data.keys()):\n",
    "    ocean_array[:, i] = dataset.ocean_data[k].sel(time=inference_date).values\n",
    "    ocean_array[:, i] = (ocean_array[:, i] - dataset.ocean_min[k]) / (\n",
    "        dataset.ocean_max[k] - dataset.ocean_min[k]\n",
    "    )\n",
    "ocean_tensor = torch.from_numpy(ocean_array)\n",
    "ocean_tensor = torch.nan_to_num(ocean_tensor)\n",
    "ocean_tensor = ocean_tensor.float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(ocean_tensor, inference_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred.reshape(X.shape).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forsea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
