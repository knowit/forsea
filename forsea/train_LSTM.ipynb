{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': 0.001,\n",
    "    'epochs': 10,\n",
    "    \"batch_accumulation\": 1,\n",
    "    'fish_types': [\"Torsk\", \"Sei\", \"Hyse\"],\n",
    "    'gear_types': [\"TrÃ¥l\"],\n",
    "    'mode': \"regression\",\n",
    "    \"sequence_len\": 50,\n",
    "    'log_target': False,\n",
    "    \"thresholds\": [1000, 1000, 1000],\n",
    "    \"criterion\": \"mse\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    'model_params': {\n",
    "        \"input_dim\": 10,\n",
    "        \"hidden_dim\": [64, 3],\n",
    "        \"kernel_size\": (3, 3),\n",
    "        \"num_layers\": 2,\n",
    "        \"batch_first\": False,\n",
    "        \"return_all_layers\": False,\n",
    "    },\n",
    "    'ocean_data_path': '../data/copernicus/datasets/norway.nc',\n",
    "    'route_data_path': '../data/VMS_DCA_joined/catch_routes.parquet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1,   200] | loss: 1884524010.587074\n",
      "[  1,   400] | loss: 274795.002388\n",
      "[  1,   600] | loss: 280841.029160\n",
      "[  1,   800] | loss: 282447.831588\n",
      "[  1,  1000] | loss: 264344.212363\n",
      "[  1,  1200] | loss: 278756.259708\n",
      "[  1,  1400] | loss: 263024.546207\n",
      "[  1,  1600] | loss: 268275.235081\n",
      "[  1,  1800] | loss: 281745.280012\n",
      "[  1,  2000] | loss: 274857.361371\n",
      "[  1,  2200] | loss: 259561.272856\n",
      "[  1,  2400] | loss: 265245.112563\n",
      "[  1,  2600] | loss: 268102.557866\n",
      "[  1,  2800] | loss: 284533.971747\n",
      "[  1,  3000] | loss: 276943.820339\n",
      "[  1,  3200] | loss: 258219.020650\n",
      "[  1,  3400] | loss: 275703.411009\n",
      "[  1,  3561] | train loss: 262611.997799 | val loss: 264781.229374\n",
      "[  2,   200] | loss: 283510.025430\n",
      "[  2,   400] | loss: 251454.098085\n",
      "[  2,   600] | loss: 256262.381702\n",
      "[  2,   800] | loss: 248952.321082\n",
      "[  2,  1000] | loss: 283504.078170\n",
      "[  2,  1200] | loss: 266259.054344\n",
      "[  2,  1400] | loss: 265923.233570\n",
      "[  2,  1600] | loss: 268179.865510\n",
      "[  2,  1800] | loss: 260104.171874\n",
      "[  2,  2000] | loss: 263319.685731\n",
      "[  2,  2200] | loss: 261805.579042\n",
      "[  2,  2400] | loss: 248027.241531\n",
      "[  2,  2600] | loss: 256603.346149\n",
      "[  2,  2800] | loss: 260151.814607\n",
      "[  2,  3000] | loss: 322280.714457\n",
      "[  2,  3200] | loss: 12997706560855731077120.000000\n",
      "[  2,  3400] | loss: nan\n",
      "[  2,  3561] | train loss: nan | val loss: nan\n",
      "[  3,   200] | loss: nan\n",
      "[  3,   400] | loss: nan\n",
      "[  3,   600] | loss: nan\n",
      "[  3,   800] | loss: nan\n",
      "[  3,  1000] | loss: nan\n",
      "[  3,  1200] | loss: nan\n",
      "[  3,  1400] | loss: nan\n",
      "[  3,  1600] | loss: nan\n",
      "[  3,  1800] | loss: nan\n",
      "[  3,  2000] | loss: nan\n",
      "[  3,  2200] | loss: nan\n",
      "[  3,  2400] | loss: nan\n",
      "[  3,  2600] | loss: nan\n",
      "[  3,  2800] | loss: nan\n",
      "[  3,  3000] | loss: nan\n",
      "[  3,  3200] | loss: nan\n",
      "[  3,  3400] | loss: nan\n",
      "[  3,  3561] | train loss: nan | val loss: nan\n",
      "[  4,   200] | loss: nan\n",
      "[  4,   400] | loss: nan\n",
      "[  4,   600] | loss: nan\n",
      "[  4,   800] | loss: nan\n",
      "[  4,  1000] | loss: nan\n",
      "[  4,  1200] | loss: nan\n",
      "[  4,  1400] | loss: nan\n",
      "[  4,  1600] | loss: nan\n",
      "[  4,  1800] | loss: nan\n",
      "[  4,  2000] | loss: nan\n",
      "[  4,  2200] | loss: nan\n",
      "[  4,  2400] | loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain_LSTM\u001b[39;00m \u001b[39mimport\u001b[39;00m train\n\u001b[0;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m train(config, run_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mGaussian_filter_LSTM\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Home_Foresee/forseeModel/forsea/train_LSTM.py:88\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config, experiment, run_name)\u001b[0m\n\u001b[1;32m     86\u001b[0m outputs \u001b[39m=\u001b[39m model(ocean_input, route_input)\n\u001b[1;32m     87\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, target)\n\u001b[0;32m---> 88\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     89\u001b[0m \u001b[39m# running_loss += loss.item()\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39m# train_samples += len(outputs)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39m# optimizer.step()\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m# optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m ((batch_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m batch_accumulation \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    102\u001b[0m     batch_idx \u001b[39m==\u001b[39m dataset\u001b[39m.\u001b[39mtrain_n \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    103\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/forsea/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/forsea/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train_LSTM import train\n",
    "\n",
    "model = train(config, run_name='Gaussian_filter_LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import ForSeaDataset\n",
    "\n",
    "dataset = ForSeaDataset(\n",
    "    config[\"ocean_data_path\"],\n",
    "    config[\"route_data_path\"],\n",
    "    fish_types=config[\"fish_types\"],\n",
    "    gear_types=config[\"gear_types\"],\n",
    "    mode=config[\"mode\"],\n",
    "    sequence_len=config[\"sequence_len\"],\n",
    "    log_target=config[\"log_target\"],\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (30,140,100) into shape (0,140,100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m a,b,c \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39mtrain_data():\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(a\u001b[39m.\u001b[39mshape, b\u001b[39m.\u001b[39mshape, c\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Home_Foresee/forseeModel/forsea/utils/dataloader.py:94\u001b[0m, in \u001b[0;36mForSeaDataset.train_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shuffle()\n\u001b[1;32m     93\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_index:\n\u001b[0;32m---> 94\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(i)\n",
      "File \u001b[0;32m~/Home_Foresee/forseeModel/forsea/utils/dataloader.py:85\u001b[0m, in \u001b[0;36mForSeaDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\n\u001b[1;32m     80\u001b[0m     \u001b[39mself\u001b[39m, idx: \u001b[39mint\u001b[39m\n\u001b[1;32m     81\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m (\n\u001b[1;32m     82\u001b[0m     \u001b[39mtuple\u001b[39m[Tensor, Iterable[Tensor], Iterable[Tensor]]\n\u001b[1;32m     83\u001b[0m     \u001b[39m|\u001b[39m \u001b[39mtuple\u001b[39m[Tensor, Tensor, Tensor]\n\u001b[1;32m     84\u001b[0m ):\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_ocean_tensor(idx)\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     86\u001b[0m     ocean_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ocean_tensor(idx)\n\u001b[1;32m     87\u001b[0m     route_batch, target_batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_route_batch(idx)\n",
      "File \u001b[0;32m~/Home_Foresee/forseeModel/forsea/utils/dataloader.py:225\u001b[0m, in \u001b[0;36mForSeaDataset._get_ocean_tensor\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    222\u001b[0m     t_stop \u001b[39m=\u001b[39m idx \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msequence_len\n\u001b[1;32m    223\u001b[0m     \u001b[39mfor\u001b[39;00m i, k \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mocean_data\u001b[39m.\u001b[39mkeys()):\n\u001b[1;32m    224\u001b[0m         \u001b[39m# TODO: Add option for different barch sizes. Currently assumes batch_size is allways one.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m         ocean_array[t_start:t_stop, \u001b[39m0\u001b[39;49m, i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scale_ocean_data(\n\u001b[1;32m    226\u001b[0m             k, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ocean_array(k, t_start, t_stop)\n\u001b[1;32m    227\u001b[0m         )\n\u001b[1;32m    228\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[39mfor\u001b[39;00m i, k \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mocean_data\u001b[39m.\u001b[39mkeys()):\n\u001b[1;32m    230\u001b[0m         \u001b[39m# TODO: Add option for different barch sizes. Currently assumes batch_size is allways one.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (30,140,100) into shape (0,140,100)"
     ]
    }
   ],
   "source": [
    "for a,b,c in dataset.train_data():\n",
    "    print(a.shape, b.shape, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 140, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.ocean_data_shape[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.GaussianFilterLSTM import ConvLSTM, LSTMAutoEncoder\n",
    "\n",
    "out_dim = len(config[\"fish_types\"])\n",
    "# model = ConvLSTM(10, [64, 64, out_dim], (3,3), num_layers=3, batch_first=False, return_all_layers=False).cuda()\n",
    "model = LSTMAutoEncoder((out_dim, *dataset.ocean_data_shape[3:]), dataset.land_mask, 10, [64, 64, out_dim], (3,3), num_layers=3, batch_first=False, return_all_layers=False).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 140, 100]) torch.Size([86, 2])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "pred = model(ocean, route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([86, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 3, 140, 100])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forsea",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
